[
  {
    "objectID": "hm_datasciende.html",
    "href": "hm_datasciende.html",
    "title": "Tennis Match Analytics (ATP & WTA, 2015–2023)",
    "section": "",
    "text": "Author: Ivan Tregub\nCourse: Data Science University: Charles University (MFF UK)\nAcademic year: 2025/2026"
  },
  {
    "objectID": "hm_datasciende.html#project-overview-and-motivation",
    "href": "hm_datasciende.html#project-overview-and-motivation",
    "title": "Tennis Match Analytics (ATP & WTA, 2015–2023)",
    "section": "Project Overview and Motivation",
    "text": "Project Overview and Motivation\nThis project analyses professional tennis matches from ATP and WTA tours in the period 2015–2023.\nThe dataset contains detailed information about tournaments, players, match outcomes and rich point-level serving statistics (aces, double faults, first serves in, break points, etc.).\nThe goal is to understand how different aspects of the game – such as court surface, match format and serving performance – are related to match outcomes and player rankings.\nThe analysis follows the CRISP-DM methodology: business understanding, data understanding, data preparation, modeling (where relevant), evaluation and conclusion."
  },
  {
    "objectID": "hm_datasciende.html#data-dictionary",
    "href": "hm_datasciende.html#data-dictionary",
    "title": "Tennis Match Analytics (ATP & WTA, 2015–2023)",
    "section": "Data Dictionary",
    "text": "Data Dictionary\nThis section provides a complete description of all columns included in the ATP & WTA match dataset (2015–2023).\n\nTournament Metadata\n\n\n\n\n\n\n\nColumn\nDescription\n\n\n\n\ntourney_id\nUnique tournament identifier (YYYY-XXX). Format varies by data source.\n\n\ntourney_name\nOfficial name of the tournament.\n\n\nsurface\nCourt surface: Hard, Clay, Grass, Carpet (rare), or missing.\n\n\ndraw_size\nNumber of players in the main draw (e.g., 32, 64, 128).\n\n\ntourney_level\nTournament category (ATP: G=Grand Slam, M=Masters 1000, A=ATP 250/500, C=Challenger; WTA: PM, P, I, ITF levels).\n\n\ntourney_date\nStart date of tournament week in YYYYMMDD format.\n\n\n\n\n\nMatch Metadata\n\n\n\nColumn\nDescription\n\n\n\n\nmatch_num\nInternal match ID within the tournament.\n\n\nscore\nMatch score in tennis format (e.g., 6-4 3-6 7-5).\n\n\nbest_of\nMatch format: 3 or 5 sets.\n\n\nround\nTournament round (R128, R64, R32, R16, QF, SF, F, etc.).\n\n\nminutes\nMatch duration in minutes (may be missing).\n\n\n\n\n\n\nWinner Information\n\n\n\n\n\n\n\nColumn\nDescription\n\n\n\n\nwinner_id\nPlayer ID of the match winner.\n\n\nwinner_seed\nSeed number of the winner.\n\n\nwinner_entry\nHow the player entered: WC=wild card, Q=qualifier, LL=lucky loser, PR=protected ranking, etc.\n\n\nwinner_name\nFull name of the winning player.\n\n\nwinner_hand\nPlaying hand: R=right-handed, L=left-handed, U=unknown.\n\n\nwinner_ht\nHeight of the winner in centimeters.\n\n\nwinner_ioc\nNationality code (ISO-3).\n\n\nwinner_age\nAge of the winner on the tournament date.\n\n\n\n\n\nWinner Serve & Performance Stats\n\n\n\nColumn\nDescription\n\n\n\n\nw_ace\nWinner’s aces.\n\n\nw_df\nWinner’s double faults.\n\n\nw_svpt\nTotal serve points played.\n\n\nw_1stIn\nFirst serves made.\n\n\nw_1stWon\nFirst-serve points won.\n\n\nw_2ndWon\nSecond-serve points won.\n\n\nw_SvGms\nServe games played.\n\n\nw_bpSaved\nBreak points saved.\n\n\nw_bpFaced\nBreak points faced.\n\n\n\n\n\nWinner Ranking\n\n\n\nColumn\nDescription\n\n\n\n\nwinner_rank\nWinner’s ATP/WTA ranking at event date.\n\n\nwinner_rank_points\nRanking points at event date.\n\n\n\n\n\n\nLoser Information\n\n\n\nColumn\nDescription\n\n\n\n\nloser_id\nPlayer ID of the losing player.\n\n\nloser_seed\nSeed number of the loser.\n\n\nloser_entry\nEntry type (Q, WC, LL, PR, etc.).\n\n\nloser_name\nFull name of the losing player.\n\n\nloser_hand\nPlaying hand.\n\n\nloser_ht\nHeight in cm.\n\n\nloser_ioc\nNationality code.\n\n\nloser_age\nAge of the loser at the tournament date.\n\n\n\n\n\nLoser Serve & Performance Stats\n\n\n\nColumn\nDescription\n\n\n\n\nl_ace\nLoser’s aces.\n\n\nl_df\nLoser’s double faults.\n\n\nl_svpt\nServe points played.\n\n\nl_1stIn\nFirst serves made.\n\n\nl_1stWon\nFirst-serve points won.\n\n\nl_2ndWon\nSecond-serve points won.\n\n\nl_SvGms\nServe games played.\n\n\nl_bpSaved\nBreak points saved.\n\n\nl_bpFaced\nBreak points faced.\n\n\n\n\n\nLoser Ranking\n\n\n\nColumn\nDescription\n\n\n\n\nloser_rank\nLoser’s ATP/WTA ranking at event date.\n\n\nloser_rank_points\nRanking points at event date.\n\n\n\n\nThis data dictionary provides a structured overview of all fields and is used as a reference throughout the analysis."
  },
  {
    "objectID": "hm_datasciende.html#objectives-and-research-questions",
    "href": "hm_datasciende.html#objectives-and-research-questions",
    "title": "Tennis Match Analytics (ATP & WTA, 2015–2023)",
    "section": "Objectives and Research Questions",
    "text": "Objectives and Research Questions\nThe main objective is to perform an exploratory data analysis (EDA) of ATP & WTA matches, quantify how match conditions and serving statistics relate to performance and winning, and then use these signals to build and evaluate models that predict match outcomes.\nMore specifically, we address the following research questions:\n\nDistribution of matches by surface\n\nHow many matches are played on each court surface (hard, clay, grass, other)?\nHow does the distribution of surfaces look over the full 2015-2023 period?\n\nMatch duration by surface\n\nWhat is the average match duration (in minutes) for each surface?\nOn which surface are matches typically the longest?\n\nServing metrics across surfaces\n\nHow do core serving metrics (double faults, first-serve percentage, second-serve performance, break-point defense) differ across surfaces?\nAre there characteristic serving profiles for hard, clay and grass courts?\n\nOutcome prediction (classification)\n\nCan we predict the match winner using pre-match or in-match statistics (rankings, surface, serve stats)?\nWhich features contribute most to predictive performance?\n\nModel evaluation and error analysis\n\n\nHow well do baseline and ML models perform (e.g., accuracy, ROC-AUC, log loss)?\nIn which match situations do models tend to fail, and what does that imply for interpretation?"
  },
  {
    "objectID": "hm_datasciende.html#loading-and-combining-all-match-data",
    "href": "hm_datasciende.html#loading-and-combining-all-match-data",
    "title": "Tennis Match Analytics (ATP & WTA, 2015–2023)",
    "section": "Loading and Combining All Match Data",
    "text": "Loading and Combining All Match Data\nIn this section, we load all available CSV files (ATP & WTA matches from 2015–2023), inspect their structure, and combine them into a single unified DataFrame.\nThis merged dataset will be the basis for all subsequent analysis.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport glob\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\npd.set_option('display.max_columns', None)\nos.chdir(\"D:/DATA SCIENCE NEW/tennis_matches\")\n\n\n\n\nCode\n# Find all CSV match files in the directory\nfiles = glob.glob(\"*.csv\")\nfiles\n\n\n['atp_matches_2015.csv',\n 'atp_matches_2016.csv',\n 'atp_matches_2017.csv',\n 'atp_matches_2018.csv',\n 'atp_matches_2019.csv',\n 'atp_matches_2020.csv',\n 'atp_matches_2021.csv',\n 'atp_matches_2022.csv',\n 'atp_matches_2023.csv',\n 'wta_matches_2015.csv',\n 'wta_matches_2016.csv',\n 'wta_matches_2017.csv',\n 'wta_matches_2018.csv',\n 'wta_matches_2019.csv',\n 'wta_matches_2020.csv',\n 'wta_matches_2021.csv',\n 'wta_matches_2022.csv',\n 'wta_matches_2023.csv']\n\n\n\n\nCode\ndfs = []\n\nfor f in files:\n    df = pd.read_csv(f)\n    df[\"source_file\"] = f     \n    dfs.append(df)\n\n# Combine all datasets\nmatches = pd.concat(dfs, ignore_index=True)\n\nmatches.head()\n\n\n\n\n\n\n\n\n\ntourney_id\ntourney_name\nsurface\ndraw_size\ntourney_level\ntourney_date\nmatch_num\nwinner_id\nwinner_seed\nwinner_entry\nwinner_name\nwinner_hand\nwinner_ht\nwinner_ioc\nwinner_age\nloser_id\nloser_seed\nloser_entry\nloser_name\nloser_hand\nloser_ht\nloser_ioc\nloser_age\nscore\nbest_of\nround\nminutes\nw_ace\nw_df\nw_svpt\nw_1stIn\nw_1stWon\nw_2ndWon\nw_SvGms\nw_bpSaved\nw_bpFaced\nl_ace\nl_df\nl_svpt\nl_1stIn\nl_1stWon\nl_2ndWon\nl_SvGms\nl_bpSaved\nl_bpFaced\nwinner_rank\nwinner_rank_points\nloser_rank\nloser_rank_points\nsource_file\n\n\n\n\n0\n2015-339\nBrisbane\nHard\n28\nA\n20150104\n1\n105357\nNaN\nWC\nJohn Millman\nR\n183.0\nAUS\n25.5\n105733\nNaN\nQ\nRhyne Williams\nR\n185.0\nUSA\n23.7\n6-3 6-1\n3\nR32\n65.0\n6.0\n2.0\n44.0\n24.0\n19.0\n14.0\n8.0\n1.0\n1.0\n3.0\n4.0\n50.0\n31.0\n20.0\n5.0\n8.0\n1.0\n5.0\n153.0\n328.0\n220.0\n221.0\natp_matches_2015.csv\n\n\n1\n2015-339\nBrisbane\nHard\n28\nA\n20150104\n2\n103813\nNaN\nNaN\nJarkko Nieminen\nL\n185.0\nFIN\n33.4\n106045\nNaN\nQ\nDenis Kudla\nR\n180.0\nUSA\n22.3\n4-6 6-1 6-4\n3\nR32\n104.0\n4.0\n0.0\n92.0\n59.0\n39.0\n17.0\n14.0\n4.0\n7.0\n6.0\n1.0\n83.0\n50.0\n26.0\n19.0\n13.0\n3.0\n8.0\n73.0\n689.0\n123.0\n440.0\natp_matches_2015.csv\n\n\n2\n2015-339\nBrisbane\nHard\n28\nA\n20150104\n3\n105902\nNaN\nWC\nJames Duckworth\nR\n183.0\nAUS\n22.9\n104468\n6.0\nNaN\nGilles Simon\nR\n183.0\nFRA\n30.0\n6-2 6-2\n3\nR32\n68.0\n4.0\n0.0\n45.0\n27.0\n20.0\n11.0\n8.0\n2.0\n3.0\n2.0\n1.0\n56.0\n37.0\n22.0\n5.0\n8.0\n10.0\n15.0\n125.0\n430.0\n21.0\n1730.0\natp_matches_2015.csv\n\n\n3\n2015-339\nBrisbane\nHard\n28\nA\n20150104\n4\n104871\nNaN\nNaN\nJeremy Chardy\nR\n188.0\nFRA\n27.8\n104979\nNaN\nNaN\nAndrey Golubev\nR\n185.0\nKAZ\n27.4\n6-4 6-4\n3\nR32\n69.0\n7.0\n1.0\n53.0\n39.0\n31.0\n11.0\n10.0\n0.0\n0.0\n9.0\n2.0\n57.0\n38.0\n30.0\n8.0\n10.0\n1.0\n3.0\n31.0\n1195.0\n72.0\n691.0\natp_matches_2015.csv\n\n\n4\n2015-339\nBrisbane\nHard\n28\nA\n20150104\n5\n105373\nNaN\nNaN\nMartin Klizan\nL\n190.0\nSVK\n25.4\n103781\nNaN\nNaN\nJurgen Melzer\nL\n183.0\nAUT\n33.6\n6-7(5) 7-6(6) 6-1\n3\nR32\n144.0\n9.0\n4.0\n130.0\n79.0\n55.0\n27.0\n16.0\n6.0\n8.0\n4.0\n4.0\n95.0\n62.0\n40.0\n19.0\n15.0\n4.0\n8.0\n34.0\n1094.0\n110.0\n505.0\natp_matches_2015.csv\n\n\n\n\n\n\n\n\n\nCode\nmatches.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 46658 entries, 0 to 46657\nData columns (total 50 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   tourney_id          46658 non-null  object \n 1   tourney_name        46658 non-null  object \n 2   surface             46658 non-null  object \n 3   draw_size           46658 non-null  int64  \n 4   tourney_level       46658 non-null  object \n 5   tourney_date        46658 non-null  int64  \n 6   match_num           46658 non-null  int64  \n 7   winner_id           46658 non-null  int64  \n 8   winner_seed         19381 non-null  object \n 9   winner_entry        6456 non-null   object \n 10  winner_name         46658 non-null  object \n 11  winner_hand         46652 non-null  object \n 12  winner_ht           44529 non-null  float64\n 13  winner_ioc          46658 non-null  object \n 14  winner_age          46649 non-null  float64\n 15  loser_id            46658 non-null  int64  \n 16  loser_seed          11272 non-null  object \n 17  loser_entry         10145 non-null  object \n 18  loser_name          46658 non-null  object \n 19  loser_hand          46624 non-null  object \n 20  loser_ht            43103 non-null  float64\n 21  loser_ioc           46658 non-null  object \n 22  loser_age           46642 non-null  float64\n 23  score               46658 non-null  object \n 24  best_of             46658 non-null  int64  \n 25  round               46658 non-null  object \n 26  minutes             40605 non-null  float64\n 27  w_ace               44327 non-null  float64\n 28  w_df                44322 non-null  float64\n 29  w_svpt              44327 non-null  float64\n 30  w_1stIn             44327 non-null  float64\n 31  w_1stWon            44327 non-null  float64\n 32  w_2ndWon            44327 non-null  float64\n 33  w_SvGms             44010 non-null  float64\n 34  w_bpSaved           44327 non-null  float64\n 35  w_bpFaced           44327 non-null  float64\n 36  l_ace               44327 non-null  float64\n 37  l_df                44322 non-null  float64\n 38  l_svpt              44327 non-null  float64\n 39  l_1stIn             44327 non-null  float64\n 40  l_1stWon            44327 non-null  float64\n 41  l_2ndWon            44327 non-null  float64\n 42  l_SvGms             44010 non-null  float64\n 43  l_bpSaved           44327 non-null  float64\n 44  l_bpFaced           44327 non-null  float64\n 45  winner_rank         46246 non-null  float64\n 46  winner_rank_points  46246 non-null  float64\n 47  loser_rank          45795 non-null  float64\n 48  loser_rank_points   45795 non-null  float64\n 49  source_file         46658 non-null  object \ndtypes: float64(27), int64(6), object(17)\nmemory usage: 17.8+ MB\n\n\n\nInitial Sanity Checks\nBefore proceeding, we check: - number of rows and columns\n- dtypes (especially tourney_date)\n- presence of missing values\n- whether numeric columns were imported correctly\n- consistency of key fields (e.g., best_of ∈ {3,5})\n\n\nCode\nmatches[\"tourney_date\"] = pd.to_datetime(matches[\"tourney_date\"], format=\"%Y%m%d\", errors=\"coerce\")\n\nmatches[\"tourney_date\"].head()\n\n\n0   2015-01-04\n1   2015-01-04\n2   2015-01-04\n3   2015-01-04\n4   2015-01-04\nName: tourney_date, dtype: datetime64[ns]\n\n\n\n\nCode\nmissing_percent = matches.isna().mean().sort_values(ascending=False)\nmissing_percent.head(20)\n\n\nwinner_entry    0.861631\nloser_entry     0.782567\nloser_seed      0.758412\nwinner_seed     0.584616\nminutes         0.129731\nloser_ht        0.076193\nl_SvGms         0.056753\nw_SvGms         0.056753\nw_df            0.050066\nl_df            0.050066\nw_1stWon        0.049959\nw_ace           0.049959\nw_bpFaced       0.049959\nw_bpSaved       0.049959\nl_svpt          0.049959\nl_1stIn         0.049959\nl_1stWon        0.049959\nw_2ndWon        0.049959\nl_2ndWon        0.049959\nl_bpSaved       0.049959\ndtype: float64\n\n\n\n\nCode\nmatches.describe(include='all').T\n\n\n\n\n\n\n\n\n\ncount\nunique\ntop\nfreq\nmean\nmin\n25%\n50%\n75%\nmax\nstd\n\n\n\n\ntourney_id\n46658\n2292\n2020-580\n254\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\ntourney_name\n46658\n1501\nAustralian Open\n2286\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nsurface\n46658\n4\nHard\n28082\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\ndraw_size\n46658.0\nNaN\nNaN\nNaN\n59.638261\n2.0\n32.0\n32.0\n96.0\n128.0\n42.561466\n\n\ntourney_level\n46658\n10\nA\n13024\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\ntourney_date\n46658\nNaN\nNaN\nNaN\n2019-03-20 15:44:39.051824128\n2015-01-04 00:00:00\n2017-01-09 00:00:00\n2019-01-14 00:00:00\n2021-08-09 00:00:00\n2023-08-28 00:00:00\nNaN\n\n\nmatch_num\n46658.0\nNaN\nNaN\nNaN\n226.057739\n1.0\n145.0\n272.0\n287.0\n2701.0\n195.749689\n\n\nwinner_id\n46658.0\nNaN\nNaN\nNaN\n160808.685906\n100644.0\n105676.0\n201314.5\n202475.0\n263853.0\n48521.068383\n\n\nwinner_seed\n19381.0\n68.0\n1.0\n1992.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nwinner_entry\n6456\n8\nQ\n3715\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nwinner_name\n46658\n1481\nNovak Djokovic\n478\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nwinner_hand\n46652\n3\nR\n40832\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nwinner_ht\n44529.0\nNaN\nNaN\nNaN\n181.269689\n155.0\n175.0\n182.0\n188.0\n211.0\n9.337922\n\n\nwinner_ioc\n46658\n110\nUSA\n4997\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nwinner_age\n46649.0\nNaN\nNaN\nNaN\n26.552475\n14.1\n23.3\n26.3\n29.5\n44.9\n4.397126\n\n\nloser_id\n46658.0\nNaN\nNaN\nNaN\n161007.790025\n100644.0\n105732.0\n201320.0\n202504.0\n263852.0\n48659.24227\n\n\nloser_seed\n11272.0\n69.0\n8.0\n914.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nloser_entry\n10145\n9\nQ\n5572\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nloser_name\n46658\n2064\nAdrian Mannarino\n230\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nloser_hand\n46624\n3\nR\n39969\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nloser_ht\n43103.0\nNaN\nNaN\nNaN\n180.691228\n154.0\n174.0\n181.0\n188.0\n211.0\n9.266405\n\n\nloser_ioc\n46658\n122\nUSA\n5048\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nloser_age\n46642.0\nNaN\nNaN\nNaN\n26.561498\n14.2\n23.2\n26.4\n29.7\n46.9\n4.521383\n\n\nscore\n46658\n6710\n6-3 6-4\n1530\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nbest_of\n46658.0\nNaN\nNaN\nNaN\n3.217412\n3.0\n3.0\n3.0\n3.0\n5.0\n0.622546\n\n\nround\n46658\n9\nR32\n14575\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nminutes\n40605.0\nNaN\nNaN\nNaN\n105.656323\n0.0\n77.0\n98.0\n129.0\n2475.0\n42.338075\n\n\nw_ace\n44327.0\nNaN\nNaN\nNaN\n5.331626\n0.0\n2.0\n4.0\n7.0\n75.0\n5.115115\n\n\nw_df\n44322.0\nNaN\nNaN\nNaN\n2.971955\n0.0\n1.0\n2.0\n4.0\n72.0\n2.498113\n\n\nw_svpt\n44327.0\nNaN\nNaN\nNaN\n74.826246\n0.0\n55.0\n70.0\n91.0\n918.0\n27.63791\n\n\nw_1stIn\n44327.0\nNaN\nNaN\nNaN\n46.880321\n0.0\n34.0\n44.0\n57.0\n702.0\n18.279316\n\n\nw_1stWon\n44327.0\nNaN\nNaN\nNaN\n33.998037\n0.0\n25.0\n32.0\n41.0\n351.0\n12.767586\n\n\nw_2ndWon\n44327.0\nNaN\nNaN\nNaN\n14.878471\n0.0\n10.0\n14.0\n18.0\n161.0\n6.423742\n\n\nw_SvGms\n44010.0\nNaN\nNaN\nNaN\n11.712293\n0.0\n9.0\n11.0\n14.0\n49.0\n4.035616\n\n\nw_bpSaved\n44327.0\nNaN\nNaN\nNaN\n3.709161\n0.0\n1.0\n3.0\n5.0\n108.0\n3.145663\n\n\nw_bpFaced\n44327.0\nNaN\nNaN\nNaN\n5.704492\n0.0\n2.0\n5.0\n8.0\n180.0\n4.306565\n\n\nl_ace\n44327.0\nNaN\nNaN\nNaN\n3.871094\n0.0\n1.0\n3.0\n5.0\n67.0\n4.432525\n\n\nl_df\n44322.0\nNaN\nNaN\nNaN\n3.657033\n0.0\n2.0\n3.0\n5.0\n36.0\n2.661933\n\n\nl_svpt\n44327.0\nNaN\nNaN\nNaN\n77.100368\n0.0\n57.0\n72.0\n93.0\n972.0\n27.686633\n\n\nl_1stIn\n44327.0\nNaN\nNaN\nNaN\n47.300787\n0.0\n34.0\n44.0\n57.0\n774.0\n18.641329\n\n\nl_1stWon\n44327.0\nNaN\nNaN\nNaN\n29.865793\n0.0\n20.0\n28.0\n37.0\n369.0\n13.768027\n\n\nl_2ndWon\n44327.0\nNaN\nNaN\nNaN\n13.123288\n0.0\n8.0\n12.0\n17.0\n74.0\n6.670109\n\n\nl_SvGms\n44010.0\nNaN\nNaN\nNaN\n11.509089\n0.0\n9.0\n11.0\n14.0\n50.0\n4.013222\n\n\nl_bpSaved\n44327.0\nNaN\nNaN\nNaN\n4.861845\n0.0\n2.0\n4.0\n7.0\n81.0\n3.250418\n\n\nl_bpFaced\n44327.0\nNaN\nNaN\nNaN\n9.209511\n0.0\n6.0\n9.0\n12.0\n180.0\n4.169997\n\n\nwinner_rank\n46246.0\nNaN\nNaN\nNaN\n75.683043\n1.0\n19.0\n46.0\n87.0\n2101.0\n120.907744\n\n\nwinner_rank_points\n46246.0\nNaN\nNaN\nNaN\n1816.192687\n1.0\n702.0\n1109.0\n2141.0\n16950.0\n1977.037348\n\n\nloser_rank\n45795.0\nNaN\nNaN\nNaN\n108.917305\n1.0\n35.0\n68.0\n115.0\n2147.0\n161.125281\n\n\nloser_rank_points\n45795.0\nNaN\nNaN\nNaN\n1186.489071\n1.0\n541.0\n845.0\n1340.0\n16950.0\n1233.859784\n\n\nsource_file\n46658\n18\natp_matches_2015.csv\n2943\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\n\nSummary of Data Loading\n\nAll CSV files were successfully detected and merged into a single DataFrame.\n\nThe final dataset contains 46,658 rows and 50 columns (will be auto-filled after matches.info().\nTournament dates were successfully converted to datetime.\nSeveral columns contain meaningful missing values (such as player height, match duration, some statistics), which will be handled later.\nThe dataset is now ready for exploratory analysis (EDA)."
  },
  {
    "objectID": "hm_datasciende.html#matches-per-court-surface",
    "href": "hm_datasciende.html#matches-per-court-surface",
    "title": "Tennis Match Analytics (ATP & WTA, 2015–2023)",
    "section": "Matches per Court Surface",
    "text": "Matches per Court Surface\nIn this section, we examine how many matches were played on each type of surface\n(Hard, Clay, Grass, Carpet).\nCourt surface is one of the most important contextual variables in tennis, as it affects play style, rally length, serve advantage, and match duration.\n\n\nCode\nsurface_counts = matches[\"surface\"].value_counts(dropna=False)\nsurface_counts\n\n\nsurface\nHard      28082\nClay      13526\nGrass      5031\nCarpet       19\nName: count, dtype: int64\n\n\n\n\nCode\nsurface_percent = (surface_counts / len(matches) * 100).round(2)\nsurface_percent\n\n\nsurface\nHard      60.19\nClay      28.99\nGrass     10.78\nCarpet     0.04\nName: count, dtype: float64\n\n\n\n\nCode\nplt.figure(figsize=(8,5))\n\nsns.barplot(\n    x=surface_counts.index,\n    y=surface_counts.values,\n    errorbar=None\n)\n\nplt.title(\"Number of Matches by Surface (2015–2023)\", fontsize=14)\nplt.xlabel(\"Surface\")\nplt.ylabel(\"Match Count\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSummary of Matches by Surface\nThe merged dataset includes 46,658 matches played between 2015 and 2023.\nThe distribution across court surfaces is as follows:\n\nHard: 28,082 matches (60.19%)\n\nClay: 13,526 matches (28.99%)\n\nGrass: 5,031 matches (10.78%)\n\nCarpet: 19 matches (0.04%)\n\nInterpretation:\nHard courts dominate the ATP/WTA calendar, accounting for roughly 60% of all matches. Clay is the second most common surface, followed by a much smaller share of grass-court matches, reflecting the short grass season. Carpet matches appear only in a negligible number of events and are largely outdated in professional tennis.\nThis distribution provides important context for later comparisons (e.g., match duration, serve statistics), as statistics on some surfaces (especially grass and carpet) rely on significantly smaller sample sizes."
  },
  {
    "objectID": "hm_datasciende.html#average-match-duration-by-surface",
    "href": "hm_datasciende.html#average-match-duration-by-surface",
    "title": "Tennis Match Analytics (ATP & WTA, 2015–2023)",
    "section": "Average Match Duration by Surface",
    "text": "Average Match Duration by Surface\nIn this section, we examine how long matches last on each type of surface.\nTennis surfaces differ in speed and rally length, which directly affects match duration:\n\nClay – typically slow, long rallies\n\nGrass – very fast, short rallies\n\nHard – medium pace, between clay and grass\n\nCarpet – fast indoor surface, almost extinct on the main tour and represented by only a few matches in the dataset\n\nWe compute the average match duration (in minutes) and then compare the surfaces.\n\n\nCode\nduration_by_surface = (\n    matches\n    .groupby(\"surface\")[\"minutes\"]\n    .mean()\n    .round(2)\n    .sort_values(ascending=False)\n)\n\nduration_by_surface\n\n\nsurface\nCarpet    122.00\nGrass     107.18\nClay      107.13\nHard      104.67\nName: minutes, dtype: float64\n\n\n\n\nCode\nplt.figure(figsize=(8,5))\n\nsns.boxplot(\n    data=matches,\n    x=\"surface\",\n    y=\"minutes\"\n)\nplt.ylim(-50, 450) \nplt.title(\"Match Duration by Surface (2015–2023)\", fontsize=14)\nplt.xlabel(\"Surface\")\nplt.ylabel(\"Minutes\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSummary of Average Match Duration\nThe mean match duration by surface (2015–2023) is:\n\nCarpet: 122.0 minutes\n\nGrass: 107.2 minutes\n\nClay: 107.1 minutes\n\nHard: 104.7 minutes\n\nCarpet technically shows the longest average match duration, but this result is based on only 19 matches, so it is not statistically reliable.\nIf we focus on the three main tour surfaces, the pattern is:\n\nGrass and clay have very similar average durations (around 107 minutes).\n\nHard courts produce slightly shorter matches on average (about 105 minutes).\n\nThis is consistent with tennis intuition: grass tends to shorten points due to fast surface speed, while clay extends rallies, but the overall match duration is also affected by scoring dynamics, player styles and tournament formats."
  },
  {
    "objectID": "hm_datasciende.html#serving-metrics-across-surfaces",
    "href": "hm_datasciende.html#serving-metrics-across-surfaces",
    "title": "Tennis Match Analytics (ATP & WTA, 2015–2023)",
    "section": "Serving Metrics Across Surfaces",
    "text": "Serving Metrics Across Surfaces\nIn this section, we analyze how key serving metrics differ across the three main tennis surfaces: hard, clay, and grass.\nSurface type has a major influence on serve effectiveness because it affects: - ball speed and bounce, - rally length, - the ability to produce aces or force return errors, - pressure on service games (break points faced and saved).\nA fast surface such as grass strongly rewards aggressive serving and produces quick points.\nA slow surface like clay reduces the impact of the serve and makes holding serve more difficult.\nHard courts sit in the middle, offering a balanced environment.\nWe examine the following serving metrics for all players (winners and losers combined):\n\nDouble faults per service game (df_per_game)\nFirst-serve percentage (1st serve pct)\nFirst-serve points won (1st serve win %)\nSecond-serve points won (2nd serve win %)\nBreak-point save percentage (bp_save_pct)\n\nWe convert the match-level data into a player-level dataset (two observations per match),\nwhich allows us to compare serving performance across surfaces consistently.\nThe goal of this section is to answer:\n\nHow does serving performance differ between hard, clay, and grass?\nWhich surface offers the strongest advantage to big servers?\nIs clay truly the most punishing surface for weak serving?\nAre break points saved and faced distributed differently across surfaces?\n\nIn the following cells, we compute all relevant serving metrics, build a player-level dataset,\nvisualize distributions by surface, and summarize the key observations.\n\n\nCode\n# Create serving metrics at match level\ndef safe_div(n, d):\n    return (n / d).replace([np.inf, -np.inf], np.nan)\n\nmatches[\"w_1st_pct\"] = safe_div(matches[\"w_1stIn\"], matches[\"w_svpt\"])\nmatches[\"l_1st_pct\"] = safe_div(matches[\"l_1stIn\"], matches[\"l_svpt\"])\n\nmatches[\"w_1stWon_pct\"] = safe_div(matches[\"w_1stWon\"], matches[\"w_1stIn\"])\nmatches[\"l_1stWon_pct\"] = safe_div(matches[\"l_1stWon\"], matches[\"l_1stIn\"])\n\n# Second-serve win %\nmatches[\"w_2ndIn_calc\"] = (matches[\"w_svpt\"] - matches[\"w_1stIn\"]).clip(lower=0)\nmatches[\"l_2ndIn_calc\"] = (matches[\"l_svpt\"] - matches[\"l_1stIn\"]).clip(lower=0)\n\nmatches[\"w_2ndWon_pct\"] = safe_div(matches[\"w_2ndWon\"], matches[\"w_2ndIn_calc\"])\nmatches[\"l_2ndWon_pct\"] = safe_div(matches[\"l_2ndWon\"], matches[\"l_2ndIn_calc\"])\n\n# Double faults per service game\nmatches[\"w_df_per_game\"] = safe_div(matches[\"w_df\"], matches[\"w_SvGms\"])\nmatches[\"l_df_per_game\"] = safe_div(matches[\"l_df\"], matches[\"l_SvGms\"])\n\n# Break-point save %\nmatches[\"w_bp_pct\"] = safe_div(matches[\"w_bpSaved\"], matches[\"w_bpFaced\"]).fillna(1.0)\nmatches[\"l_bp_pct\"] = safe_div(matches[\"l_bpSaved\"], matches[\"l_bpFaced\"]).fillna(1.0)\n\n\n\n\nCode\n# Build player-level dataset for surface comparisons\ndf_surface = pd.DataFrame({\n    \"surface\": pd.concat([matches[\"surface\"], matches[\"surface\"]]),\n    \n    \"df_per_game\": pd.concat([matches[\"w_df_per_game\"], matches[\"l_df_per_game\"]]),\n    \"first_serve_pct\": pd.concat([matches[\"w_1st_pct\"], matches[\"l_1st_pct\"]]),\n    \"first_serve_win_pct\": pd.concat([matches[\"w_1stWon_pct\"], matches[\"l_1stWon_pct\"]]),\n    \"second_serve_win_pct\": pd.concat([matches[\"w_2ndWon_pct\"], matches[\"l_2ndWon_pct\"]]),\n    \"bp_save_pct\": pd.concat([matches[\"w_bp_pct\"], matches[\"l_bp_pct\"]]),\n})\n\n\n\n\nCode\nsurface_summary = df_surface.groupby(\"surface\").mean().round(3)\nsurface_summary\n\n\n\n\n\n\n\n\n\ndf_per_game\nfirst_serve_pct\nfirst_serve_win_pct\nsecond_serve_win_pct\nbp_save_pct\n\n\nsurface\n\n\n\n\n\n\n\n\n\nCarpet\n0.343\n0.604\n0.688\n0.494\n0.572\n\n\nClay\n0.274\n0.628\n0.657\n0.484\n0.577\n\n\nGrass\n0.286\n0.626\n0.705\n0.497\n0.599\n\n\nHard\n0.299\n0.614\n0.683\n0.485\n0.600\n\n\n\n\n\n\n\n\n\nCode\ndf_surface = df_surface.reset_index(drop=True)\n\nmetrics = [\n    \"df_per_game\",\n    \"first_serve_pct\",\n    \"first_serve_win_pct\",\n    \"second_serve_win_pct\",\n    \"bp_save_pct\"\n]\n\nplt.figure(figsize=(16, 10))\n\nfor i, metric in enumerate(metrics, 1):\n    plt.subplot(2, 3, i)\n    sns.boxplot(data=df_surface, x=\"surface\", y=metric)\n    plt.title(metric.replace(\"_\", \" \").title())\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nsurface_summary\n\n\n\n\n\n\n\n\n\ndf_per_game\nfirst_serve_pct\nfirst_serve_win_pct\nsecond_serve_win_pct\nbp_save_pct\n\n\nsurface\n\n\n\n\n\n\n\n\n\nCarpet\n0.343\n0.604\n0.688\n0.494\n0.572\n\n\nClay\n0.274\n0.628\n0.657\n0.484\n0.577\n\n\nGrass\n0.286\n0.626\n0.705\n0.497\n0.599\n\n\nHard\n0.299\n0.614\n0.683\n0.485\n0.600\n\n\n\n\n\n\n\n\nSummary: Serving Metrics by Surface\nHard courts - Balanced serving profile - Moderate double faults, strong first-serve %, strong BP saving\nClay courts - Lowest ace rate, lowest first-serve win %, most break points faced - Defensive surface → harder to win short points\nGrass courts - Highest first-serve win % - Strongest second-serve win % - Break points rarely faced → serve is most dominant - Highest double-fault rate per service game (aggressive serving)\n\n\nKey insights\n\nGrass strongly favors big servers: both 1st and 2nd serve win % peak here.\nClay punishes weak serve performance: lowest serve efficiency metrics.\nHard is a balanced middle point."
  },
  {
    "objectID": "hm_datasciende.html#machine-learning-problem-formulation-and-evaluation-plan",
    "href": "hm_datasciende.html#machine-learning-problem-formulation-and-evaluation-plan",
    "title": "Tennis Match Analytics (ATP & WTA, 2015–2023)",
    "section": "Machine Learning: Problem Formulation and Evaluation Plan",
    "text": "Machine Learning: Problem Formulation and Evaluation Plan\nWe extend the analysis with a predictive task that estimates the probability of winning a match.\n\nTarget and prediction setting- Target: won (1 = winner, 0 = loser) at match level.\n\nPre-match setting: only features known before the match (rankings, surface, tournament level, season, player age/handedness).\nPost-match diagnostic setting: use in-match serve stats to explain outcomes (not for true pre-match prediction).\n\n\n\nFeatures and preprocessing- Encode categorical features (surface, tournament level) and scale numeric features.\n\nHandle missing values; remove obvious leakage fields (score, winner/loser names).\nFor pre-match models, reshape into player vs opponent features (e.g., rank_diff) without using winner/loser labels.\n\n\n\nBaselines and models- Baselines: majority class, logistic regression.\n\nCandidate models: regularized logistic regression, random forest, gradient boosting.\n\n\n\nEvaluation and error analysis- Time-aware split by season for train/validation/test.\n\nMetrics: accuracy, ROC-AUC, log loss; include calibration curves.\nError analysis by surface, rank gap, and match duration.\n\n\n\nModeling dataset and split\n\nPrepare season and serve metrics\n\n\nCode\n# 6.5.1 Prepare season and serve metrics\nif \"tourney_date\" in matches.columns:\n    matches[\"tourney_date\"] = pd.to_datetime(matches[\"tourney_date\"], errors=\"coerce\")\n\nmatches[\"season\"] = matches[\"tourney_date\"].dt.year\n\n\ndef safe_div(n, d):\n    return (n / d).replace([np.inf, -np.inf], np.nan)\n\n\n# Ensure serve metrics exist (used by diagnostic models)\nif \"w_1st_pct\" not in matches.columns:\n    matches[\"w_1st_pct\"] = safe_div(matches[\"w_1stIn\"], matches[\"w_svpt\"])\n    matches[\"l_1st_pct\"] = safe_div(matches[\"l_1stIn\"], matches[\"l_svpt\"])\n\nif \"w_1stWon_pct\" not in matches.columns:\n    matches[\"w_1stWon_pct\"] = safe_div(matches[\"w_1stWon\"], matches[\"w_1stIn\"])\n    matches[\"l_1stWon_pct\"] = safe_div(matches[\"l_1stWon\"], matches[\"l_1stIn\"])\n\nif \"w_2ndIn_calc\" not in matches.columns:\n    matches[\"w_2ndIn_calc\"] = (matches[\"w_svpt\"] - matches[\"w_1stIn\"]).clip(lower=0)\n    matches[\"l_2ndIn_calc\"] = (matches[\"l_svpt\"] - matches[\"l_1stIn\"]).clip(lower=0)\n\nif \"w_2ndWon_pct\" not in matches.columns:\n    matches[\"w_2ndWon_pct\"] = safe_div(matches[\"w_2ndWon\"], matches[\"w_2ndIn_calc\"])\n    matches[\"l_2ndWon_pct\"] = safe_div(matches[\"l_2ndWon\"], matches[\"l_2ndIn_calc\"])\n\nif \"w_df_per_game\" not in matches.columns:\n    matches[\"w_df_per_game\"] = safe_div(matches[\"w_df\"], matches[\"w_SvGms\"])\n    matches[\"l_df_per_game\"] = safe_div(matches[\"l_df\"], matches[\"l_SvGms\"])\n\nif \"w_bp_pct\" not in matches.columns:\n    matches[\"w_bp_pct\"] = safe_div(matches[\"w_bpSaved\"], matches[\"w_bpFaced\"]).fillna(1.0)\n    matches[\"l_bp_pct\"] = safe_div(matches[\"l_bpSaved\"], matches[\"l_bpFaced\"]).fillna(1.0)\n\nprint(f\"Matches: {len(matches):,} | Seasons: {matches['season'].nunique():,}\")\n\n\nMatches: 46,658 | Seasons: 9\n\n\n\n\nBuild player and opponent rows\n\n\nCode\n# 6.5.2 Build player and opponent rows\nbase_cols = [c for c in [\n    \"tourney_date\", \"season\", \"surface\", \"tourney_level\", \"best_of\", \"round\", \"minutes\"\n] if c in matches.columns]\n\nmeta_map = {\n    \"rank\": (\"winner_rank\", \"loser_rank\"),\n    \"rank_points\": (\"winner_rank_points\", \"loser_rank_points\"),\n    \"seed\": (\"winner_seed\", \"loser_seed\"),\n    \"entry\": (\"winner_entry\", \"loser_entry\"),\n    \"hand\": (\"winner_hand\", \"loser_hand\"),\n    \"ht\": (\"winner_ht\", \"loser_ht\"),\n    \"age\": (\"winner_age\", \"loser_age\"),\n}\n\nserve_map = {\n    \"1st_pct\": (\"w_1st_pct\", \"l_1st_pct\"),\n    \"1stWon_pct\": (\"w_1stWon_pct\", \"l_1stWon_pct\"),\n    \"2ndWon_pct\": (\"w_2ndWon_pct\", \"l_2ndWon_pct\"),\n    \"df_per_game\": (\"w_df_per_game\", \"l_df_per_game\"),\n    \"bp_pct\": (\"w_bp_pct\", \"l_bp_pct\"),\n}\n\n\ndef build_rows(df, is_winner, include_serve=False):\n    data = {col: df[col] for col in base_cols}\n\n    for suffix, (w_col, l_col) in meta_map.items():\n        if w_col in df.columns and l_col in df.columns:\n            if is_winner:\n                data[f\"player_{suffix}\"] = df[w_col]\n                data[f\"opponent_{suffix}\"] = df[l_col]\n            else:\n                data[f\"player_{suffix}\"] = df[l_col]\n                data[f\"opponent_{suffix}\"] = df[w_col]\n\n    if include_serve:\n        for suffix, (w_col, l_col) in serve_map.items():\n            if w_col in df.columns and l_col in df.columns:\n                if is_winner:\n                    data[f\"player_{suffix}\"] = df[w_col]\n                    data[f\"opponent_{suffix}\"] = df[l_col]\n                else:\n                    data[f\"player_{suffix}\"] = df[l_col]\n                    data[f\"opponent_{suffix}\"] = df[w_col]\n\n    data[\"won\"] = 1 if is_winner else 0\n    return pd.DataFrame(data)\n\n\ndf_pre = pd.concat(\n    [build_rows(matches, True, include_serve=False),\n     build_rows(matches, False, include_serve=False)],\n    ignore_index=True,\n)\n\ndf_diag = pd.concat(\n    [build_rows(matches, True, include_serve=True),\n     build_rows(matches, False, include_serve=True)],\n    ignore_index=True,\n)\n\nprint(f\"Pre-match rows: {len(df_pre):,} | Diagnostic rows: {len(df_diag):,}\")\n\n\nPre-match rows: 93,316 | Diagnostic rows: 93,316\n\n\n\n\nAdd differential features\n\n\nCode\n# 6.5.3 Add differential features\n\ndef coerce_numeric(df, cols):\n    for col in cols:\n        if col in df.columns:\n            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n    return df\n\n\ndef replace_inf(df, cols):\n    for col in cols:\n        if col in df.columns:\n            df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n    return df\n\n\ndef add_diffs(df, suffixes):\n    for suffix in suffixes:\n        p = f\"player_{suffix}\"\n        o = f\"opponent_{suffix}\"\n        if p in df.columns and o in df.columns:\n            df[p] = pd.to_numeric(df[p], errors=\"coerce\")\n            df[o] = pd.to_numeric(df[o], errors=\"coerce\")\n            df[f\"{suffix}_diff\"] = df[p] - df[o]\n    return df\n\n\ndiff_suffixes = [\n    \"rank\", \"rank_points\", \"seed\", \"age\", \"ht\",\n    \"1st_pct\", \"1stWon_pct\", \"2ndWon_pct\", \"df_per_game\", \"bp_pct\",\n]\n\ndf_pre = add_diffs(df_pre, diff_suffixes)\n\ndf_diag = add_diffs(df_diag, diff_suffixes)\n\nnumeric_base = [\"best_of\", \"season\", \"minutes\"]\nnumeric_cols = (\n    numeric_base\n    + [f\"player_{s}\" for s in diff_suffixes]\n    + [f\"opponent_{s}\" for s in diff_suffixes]\n    + [f\"{s}_diff\" for s in diff_suffixes]\n)\n\ndf_pre = coerce_numeric(df_pre, numeric_cols)\n\ndf_diag = coerce_numeric(df_diag, numeric_cols)\n\ndf_pre = replace_inf(df_pre, numeric_cols)\n\ndf_diag = replace_inf(df_diag, numeric_cols)\n\nprint(f\"Pre-match shape: {df_pre.shape} | Diagnostic shape: {df_diag.shape}\")\n\n\nPre-match shape: (93316, 27) | Diagnostic shape: (93316, 42)\n\n\n\n\n\nTrain, validate, and test models\n\nImports and helper functions\n\n\nCode\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, roc_auc_score, log_loss\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.base import clone\nfrom IPython.display import display\n\n\ndef make_ohe():\n    ohe_kwargs = {\"handle_unknown\": \"ignore\"}\n    if \"sparse_output\" in OneHotEncoder().get_params():\n        ohe_kwargs[\"sparse_output\"] = False\n    else:\n        ohe_kwargs[\"sparse\"] = False\n    return OneHotEncoder(**ohe_kwargs)\n\n\ndef time_split(df, season_col=\"season\"):\n    seasons = sorted(df[season_col].dropna().unique())\n    if len(seasons) &lt; 3:\n        raise ValueError(\"Need at least 3 seasons for train/val/test split.\")\n    train_seasons = seasons[:-2]\n    val_season = seasons[-2]\n    test_season = seasons[-1]\n    df_train = df[df[season_col].isin(train_seasons)].copy()\n    df_val = df[df[season_col] == val_season].copy()\n    df_test = df[df[season_col] == test_season].copy()\n    return df_train, df_val, df_test, train_seasons, val_season, test_season\n\n\ndef build_feature_lists(df, extra_numeric=None):\n    categorical = [\n        \"surface\",\n        \"tourney_level\",\n        \"round\",\n        \"player_hand\",\n        \"opponent_hand\",\n        \"player_entry\",\n        \"opponent_entry\",\n    ]\n    numeric = [\n        \"best_of\",\n        \"season\",\n        \"player_rank\",\n        \"opponent_rank\",\n        \"rank_diff\",\n        \"player_rank_points\",\n        \"opponent_rank_points\",\n        \"rank_points_diff\",\n        \"player_seed\",\n        \"opponent_seed\",\n        \"seed_diff\",\n        \"player_age\",\n        \"opponent_age\",\n        \"age_diff\",\n        \"player_ht\",\n        \"opponent_ht\",\n        \"ht_diff\",\n    ]\n    if extra_numeric:\n        numeric = numeric + extra_numeric\n\n    categorical = [c for c in categorical if c in df.columns]\n    numeric = [c for c in numeric if c in df.columns]\n    return categorical, numeric\n\n\ndef evaluate_metrics(y_true, probs):\n    probs = np.asarray(probs)\n    probs = np.clip(probs, 1e-6, 1 - 1e-6)\n    preds = (probs &gt;= 0.5).astype(int)\n    return {\n        \"accuracy\": accuracy_score(y_true, preds),\n        \"roc_auc\": roc_auc_score(y_true, probs),\n        \"log_loss\": log_loss(y_true, probs),\n    }\n\n\n\n\nTraining and evaluation routine\n\n\nCode\ndef run_experiment(df_train, df_val, df_test, categorical, numeric, label):\n    feature_cols = categorical + numeric\n    if not feature_cols:\n        raise ValueError(\"No features available for modeling.\")\n\n    for df_ in (df_train, df_val, df_test):\n        for col in numeric:\n            if col in df_.columns:\n                df_[col] = pd.to_numeric(df_[col], errors=\"coerce\")\n                df_[col] = df_[col].replace([np.inf, -np.inf], np.nan)\n\n    X_train = df_train[feature_cols]\n    y_train = df_train[\"won\"].astype(int)\n    X_val = df_val[feature_cols]\n    y_val = df_val[\"won\"].astype(int)\n    X_test = df_test[feature_cols]\n    y_test = df_test[\"won\"].astype(int)\n\n    numeric_transformer = Pipeline(\n        steps=[\n            (\"imputer\", SimpleImputer(strategy=\"median\")),\n            (\"scaler\", StandardScaler()),\n        ]\n    )\n    categorical_transformer = Pipeline(\n        steps=[\n            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n            (\"onehot\", make_ohe()),\n        ]\n    )\n\n    def make_preprocess():\n        return ColumnTransformer(\n            transformers=[\n                (\"num\", numeric_transformer, numeric),\n                (\"cat\", categorical_transformer, categorical),\n            ]\n        )\n\n    models = {\n        \"log_reg\": LogisticRegression(max_iter=1000, class_weight=\"balanced\"),\n        \"rf\": RandomForestClassifier(\n            n_estimators=300, random_state=42, n_jobs=-1, class_weight=\"balanced\"\n        ),\n        \"gb\": GradientBoostingClassifier(random_state=42),\n    }\n\n    val_rows = []\n    base_prob = y_train.mean()\n    val_rows.append({\n        \"model\": \"baseline\",\n        **evaluate_metrics(y_val, np.full(len(y_val), base_prob)),\n    })\n\n    for name, model in models.items():\n        pipe = Pipeline([\n            (\"preprocess\", make_preprocess()),\n            (\"model\", clone(model)),\n        ])\n        pipe.fit(X_train, y_train)\n        val_probs = pipe.predict_proba(X_val)[:, 1]\n        metrics = evaluate_metrics(y_val, val_probs)\n        metrics[\"model\"] = name\n        val_rows.append(metrics)\n\n    val_df = pd.DataFrame(val_rows).sort_values(\"roc_auc\", ascending=False)\n\n    model_rows = [r for r in val_rows if r[\"model\"] != \"baseline\"]\n    best_name = max(model_rows, key=lambda r: r[\"roc_auc\"])[\"model\"]\n\n    X_trainval = pd.concat([X_train, X_val], axis=0)\n    y_trainval = pd.concat([y_train, y_val], axis=0)\n    base_prob_test = y_trainval.mean()\n\n    test_rows = []\n    test_rows.append({\n        \"model\": \"baseline\",\n        **evaluate_metrics(y_test, np.full(len(y_test), base_prob_test)),\n    })\n\n    best_pipe = None\n    best_test_probs = None\n\n    for name, model in models.items():\n        pipe = Pipeline([\n            (\"preprocess\", make_preprocess()),\n            (\"model\", clone(model)),\n        ])\n        pipe.fit(X_trainval, y_trainval)\n        test_probs = pipe.predict_proba(X_test)[:, 1]\n        metrics = evaluate_metrics(y_test, test_probs)\n        metrics[\"model\"] = name\n        test_rows.append(metrics)\n\n        if name == best_name:\n            best_pipe = pipe\n            best_test_probs = test_probs\n\n    test_df = pd.DataFrame(test_rows).sort_values(\"roc_auc\", ascending=False)\n\n    val_season = df_val[\"season\"].dropna().unique()\n    test_season = df_test[\"season\"].dropna().unique()\n    val_label = val_season[0] if len(val_season) else \"n/a\"\n    test_label = test_season[0] if len(test_season) else \"n/a\"\n    print(f\"{label} split: train seasons={len(set(df_train['season']))}, val={val_label}, test={test_label}\")\n\n    return val_df, test_df, best_name, best_pipe, best_test_probs\n\n\n\n\nPre-match experiment results\n\n\nCode\npre_train, pre_val, pre_test, train_seasons, val_season, test_season = time_split(df_pre)\npre_cats, pre_nums = build_feature_lists(df_pre)\npre_val_df, pre_test_df, pre_best_name, pre_best_pipe, pre_best_test_probs = run_experiment(\n    pre_train, pre_val, pre_test, pre_cats, pre_nums, label=\"Pre-match\"\n)\n\ndisplay(pre_val_df)\ndisplay(pre_test_df)\n\n\nPre-match split: train seasons=7, val=2022, test=2023\n\n\n\n\n\n\n\n\n\nmodel\naccuracy\nroc_auc\nlog_loss\n\n\n\n\n3\ngb\n0.644620\n0.703287\n0.626205\n\n\n1\nlog_reg\n0.646707\n0.701644\n0.628427\n\n\n2\nrf\n0.637725\n0.695617\n0.630537\n\n\n0\nbaseline\n0.500000\n0.500000\n0.693147\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel\naccuracy\nroc_auc\nlog_loss\n\n\n\n\n3\ngb\n0.638614\n0.701283\n0.626402\n\n\n2\nrf\n0.637107\n0.698516\n0.628147\n\n\n1\nlog_reg\n0.642058\n0.697928\n0.632324\n\n\n0\nbaseline\n0.500000\n0.500000\n0.693147\n\n\n\n\n\n\n\n\n\n\nDiagnostic model with in-match serve stats\n\nDiagnostic feature set\n\n\nCode\nserve_numeric = [\n    \"player_1st_pct\", \"opponent_1st_pct\", \"1st_pct_diff\",\n    \"player_1stWon_pct\", \"opponent_1stWon_pct\", \"1stWon_pct_diff\",\n    \"player_2ndWon_pct\", \"opponent_2ndWon_pct\", \"2ndWon_pct_diff\",\n    \"player_df_per_game\", \"opponent_df_per_game\", \"df_per_game_diff\",\n    \"player_bp_pct\", \"opponent_bp_pct\", \"bp_pct_diff\",\n]\n\n\n\n\nDiagnostic results\n\n\nCode\n# Diagnostic experiment (uses in-match serve metrics)\ndiag_train, diag_val, diag_test, _, _, _ = time_split(df_diag)\ndiag_cats, diag_nums = build_feature_lists(df_diag, extra_numeric=serve_numeric)\ndiag_val_df, diag_test_df, diag_best_name, diag_best_pipe, diag_best_test_probs = run_experiment(\n    diag_train, diag_val, diag_test, diag_cats, diag_nums, label=\"Diagnostic\"\n)\n\ndisplay(diag_val_df)\ndisplay(diag_test_df)\n\n\nDiagnostic split: train seasons=7, val=2022, test=2023\n\n\n\n\n\n\n\n\n\nmodel\naccuracy\nroc_auc\nlog_loss\n\n\n\n\n3\ngb\n0.923154\n0.981383\n0.177271\n\n\n2\nrf\n0.921067\n0.979595\n0.208583\n\n\n1\nlog_reg\n0.919252\n0.979156\n0.186643\n\n\n0\nbaseline\n0.500000\n0.500000\n0.693147\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel\naccuracy\nroc_auc\nlog_loss\n\n\n\n\n3\ngb\n0.922406\n0.980359\n0.183314\n\n\n1\nlog_reg\n0.920362\n0.979093\n0.187765\n\n\n2\nrf\n0.920146\n0.978705\n0.212425\n\n\n0\nbaseline\n0.500000\n0.500000\n0.693147\n\n\n\n\n\n\n\n\n\n\nCalibration and error analysis (pre-match model)\n\nCalibration curve\n\n\nCode\nfrom sklearn.calibration import calibration_curve\n\nanalysis = pre_test.copy()\nanalysis = analysis.reset_index(drop=True)\n\nprobs = np.asarray(pre_best_test_probs)\nif probs.ndim != 1:\n    probs = probs.ravel()\nif len(probs) != len(analysis):\n    raise ValueError(\"Prediction length does not match test set length.\")\n\nanalysis[\"pred_prob\"] = pd.to_numeric(probs, errors=\"coerce\")\nanalysis[\"won\"] = pd.to_numeric(analysis[\"won\"], errors=\"coerce\")\nanalysis = analysis.dropna(subset=[\"pred_prob\", \"won\"])\nanalysis[\"pred\"] = (analysis[\"pred_prob\"] &gt;= 0.5).astype(int)\nanalysis[\"error\"] = (analysis[\"pred\"] != analysis[\"won\"]).astype(int)\n\n# Calibration curve\nprob_true, prob_pred = calibration_curve(analysis[\"won\"], analysis[\"pred_prob\"], n_bins=10)\nplt.figure(figsize=(6, 4))\nplt.plot(prob_pred, prob_true, marker=\"o\", label=\"Model\")\nplt.plot([0, 1], [0, 1], \"--\", color=\"gray\", label=\"Perfectly calibrated\")\nplt.title(f\"Calibration curve ({pre_best_name})\")\nplt.xlabel(\"Predicted win probability\")\nplt.ylabel(\"Observed win rate\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nError analysis slices\n\n\nCode\n# Error analysis by surface\nif \"surface\" in analysis.columns:\n    error_by_surface = (\n        analysis.groupby(\"surface\")[\"error\"]\n        .agg([\"mean\", \"count\"])\n        .sort_values(\"mean\", ascending=False)\n    )\n    display(error_by_surface)\n\n# Error analysis by rank gap\nif \"rank_diff\" in analysis.columns:\n    analysis[\"rank_diff\"] = pd.to_numeric(analysis[\"rank_diff\"], errors=\"coerce\")\n    analysis[\"rank_gap\"] = analysis[\"rank_diff\"].abs()\n    bins = [0, 25, 50, 100, 200, 500, np.inf]\n    labels = [\"0-25\", \"25-50\", \"50-100\", \"100-200\", \"200-500\", \"500+\"]\n    analysis[\"rank_gap_bin\"] = pd.cut(analysis[\"rank_gap\"], bins=bins, labels=labels, include_lowest=True)\n    error_by_rank_gap = (\n        analysis.groupby(\"rank_gap_bin\", observed=False)[\"error\"]\n        .agg([\"mean\", \"count\"])\n        .sort_values(\"mean\", ascending=False)\n    )\n    display(error_by_rank_gap)\n\n# Error analysis by match duration\nif \"minutes\" in analysis.columns:\n    analysis[\"minutes\"] = pd.to_numeric(analysis[\"minutes\"], errors=\"coerce\")\n    analysis[\"minutes\"] = analysis[\"minutes\"].clip(lower=0)\n    bins = [0, 60, 90, 120, 150, 200, np.inf]\n    labels = [\"0-60\", \"60-90\", \"90-120\", \"120-150\", \"150-200\", \"200+\"]\n    analysis[\"minutes_bin\"] = pd.cut(analysis[\"minutes\"], bins=bins, labels=labels, include_lowest=True)\n    error_by_minutes = (\n        analysis.groupby(\"minutes_bin\", observed=False)[\"error\"]\n        .agg([\"mean\", \"count\"])\n        .sort_values(\"mean\", ascending=False)\n    )\n    display(error_by_minutes)\n\n\n\n\n\n\n\n\n\nmean\ncount\n\n\nsurface\n\n\n\n\n\n\nGrass\n0.377551\n1274\n\n\nClay\n0.373045\n3324\n\n\nHard\n0.348743\n4694\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmean\ncount\n\n\nrank_gap_bin\n\n\n\n\n\n\n0-25\n0.439112\n2792\n\n\n25-50\n0.369671\n2064\n\n\n50-100\n0.342731\n2270\n\n\n100-200\n0.308436\n1138\n\n\n500+\n0.226277\n274\n\n\n200-500\n0.217857\n560\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmean\ncount\n\n\nminutes_bin\n\n\n\n\n\n\n200+\n0.444954\n218\n\n\n150-200\n0.442440\n1164\n\n\n120-150\n0.394289\n1646\n\n\n90-120\n0.380474\n2192\n\n\n0-60\n0.331683\n404\n\n\n60-90\n0.298567\n2512"
  },
  {
    "objectID": "hm_datasciende.html#conclusions",
    "href": "hm_datasciende.html#conclusions",
    "title": "Tennis Match Analytics (ATP & WTA, 2015–2023)",
    "section": "Conclusions",
    "text": "Conclusions\n\nEDA conclusions\n\nHard courts dominate the sample (~60%), with clay ~29% and grass ~11%. Carpet is negligible.\nAverage match duration is higher on clay/grass than hard; carpet averages are unstable due to a tiny sample.\nSurface profiles differ in serving metrics: first-serve percentage peaks on clay, while first- and second-serve win rates peak on grass. Break-point save rates are highest on hard/grass.\n\n\n\nML conclusions\n\nPre-match models achieve moderate discrimination (ROC-AUC ~0.70), showing that pre-match features explain part of outcomes.\nDiagnostic models using in-match serve stats are much stronger (ROC-AUC ~0.98), confirming that serve performance largely explains outcomes but is not available pre-match.\nErrors cluster in close-rank matches (rank gap 0-25) and very long matches (200+ minutes), with grass the hardest surface in this analysis.\n\n\n\nFinal narrative summary\nThis report provides a compact EDA of surface distribution, match duration, and serving profiles across surfaces, then extends to match outcome prediction. The EDA confirms clear surface effects, while modeling shows moderate pre-match predictability and strong diagnostic performance when in-match serve stats are included. Error analysis highlights the most challenging cases (tight rank gaps and very long matches), providing guidance for future feature engineering and model refinement."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tennis Match Analytics",
    "section": "",
    "text": "This Quarto project consolidates the exploratory analysis and the ML-based match outcome prediction into a single, reproducible report.\nCore goals\n\nDistribution of matches by surface.\nMatch duration by surface.\nServing metrics across surfaces.\nMatch outcome prediction (pre-match and diagnostic settings)."
  },
  {
    "objectID": "index.html#project-overview",
    "href": "index.html#project-overview",
    "title": "Tennis Match Analytics",
    "section": "",
    "text": "This Quarto project consolidates the exploratory analysis and the ML-based match outcome prediction into a single, reproducible report.\nCore goals\n\nDistribution of matches by surface.\nMatch duration by surface.\nServing metrics across surfaces.\nMatch outcome prediction (pre-match and diagnostic settings)."
  },
  {
    "objectID": "index.html#data",
    "href": "index.html#data",
    "title": "Tennis Match Analytics",
    "section": "Data",
    "text": "Data\nThe analysis is based on ATP & WTA match data from 2015-2023. Raw CSV files are loaded from D:/DATA SCIENCE NEW/tennis_matches."
  },
  {
    "objectID": "index.html#reports",
    "href": "index.html#reports",
    "title": "Tennis Match Analytics",
    "section": "Reports",
    "text": "Reports\n\nFull Report: The complete notebook with EDA, modeling, and diagnostics.\n\nOpen the full report"
  },
  {
    "objectID": "index.html#final-narrative-summary",
    "href": "index.html#final-narrative-summary",
    "title": "Tennis Match Analytics",
    "section": "Final narrative summary",
    "text": "Final narrative summary\nThis report provides a compact EDA of surface distribution, match duration, and serving profiles across surfaces, then extends to match outcome prediction. The EDA confirms clear surface effects, while modeling shows moderate pre-match predictability and strong diagnostic performance when in-match serve stats are included. Error analysis highlights the most challenging cases (tight rank gaps and very long matches), providing guidance for future feature engineering and model refinement."
  }
]